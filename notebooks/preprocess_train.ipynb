{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display settings\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set_palette('coolwarm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Loading the Dataset\n",
    "df = pd.read_csv('../data/Housing.csv')\n",
    "print('Dataset Loaded Successfully!')\n",
    "print('Shape of the dataset:', df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 3. Data Exploration and EDA\n",
    "\n",
    "# Checking for missing values\n",
    "print('\\nMissing Values:')\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Summary statistics\n",
    "print('\\nSummary Statistics:')\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types\n",
    "print('\\nData Types:')\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "encoded_df = pd.get_dummies(df, drop_first=True)\n",
    "sns.heatmap(encoded_df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Engineering Completed:\n",
      "   total_rooms  luxury_count furnishingstatus  furnishingstatus_encoded\n",
      "0           11             2        furnished                         2\n",
      "1           15             1        furnished                         2\n",
      "2            9             1   semi-furnished                         1\n",
      "3           11             2        furnished                         2\n",
      "4            9             2        furnished                         2\n"
     ]
    }
   ],
   "source": [
    "#Feature Engineering\n",
    "# Creating total rooms feature\n",
    "df['total_rooms'] = df['bedrooms'] + df['bathrooms'] + df['stories'] + df['parking']\n",
    "\n",
    "# Creating luxury feature count\n",
    "df['luxury_count'] = (df['airconditioning'] == 'yes').astype(int) + \\\n",
    "                     (df['guestroom'] == 'yes').astype(int) + \\\n",
    "                     (df['hotwaterheating'] == 'yes').astype(int) + \\\n",
    "                     (df['prefarea'] == 'yes').astype(int)\n",
    "\n",
    "# Encoding furnishing status as an ordinal value\n",
    "furnishing_mapping = {'unfurnished': 0, 'semi-furnished': 1, 'furnished': 2}\n",
    "df['furnishingstatus_encoded'] = df['furnishingstatus'].map(furnishing_mapping)\n",
    "\n",
    "print('\\nFeature Engineering Completed:')\n",
    "print(df[['total_rooms', 'luxury_count', 'furnishingstatus', 'furnishingstatus_encoded']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df[['area', 'total_rooms', 'luxury_count', 'furnishingstatus_encoded']]\n",
    "Y = df['price']\n",
    "\n",
    "# Encoding categorical features\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Model Training and Evaluation\n",
    "\n",
    "def evaluate_model(model, X_train, X_test, Y_train, Y_test):\n",
    "    model.fit(X_train, Y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(Y_test, predictions))\n",
    "    mae = mean_absolute_error(Y_test, predictions)\n",
    "    r2 = r2_score(Y_test, predictions)\n",
    "    print(f'Model: {model.__class__.__name__}')\n",
    "    print(f'RMSE: {rmse:.2f}, MAE: {mae:.2f}, R²: {r2:.2f}\\n')\n",
    "    return model, rmse, mae, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Pipeline\n",
      "RMSE: 1345743.53, MAE: 960709.25, R²: 0.64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "lr = Pipeline(steps=[('preprocessor', column_transformer), ('regressor', LinearRegression())])\n",
    "lr_model, lr_rmse, lr_mae, lr_r2 = evaluate_model(lr, X_train, X_test, Y_train, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Pipeline\n",
      "RMSE: 1391299.92, MAE: 988261.81, R²: 0.62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = Pipeline(steps=[('preprocessor', column_transformer), ('regressor', RandomForestRegressor())])\n",
    "rf_model, rf_rmse, rf_mae, rf_r2 = evaluate_model(rf, X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Linear Regression: {'regressor__fit_intercept': False}\n",
      "Best Score (MSE): 1164950298392.1943\n"
     ]
    }
   ],
   "source": [
    "## 6. Model Optimization (Linear Regression)\n",
    "\n",
    "param_grid_lr = {\n",
    "    'regressor__fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "grid_search_lr = GridSearchCV(lr, param_grid_lr, cv=5, scoring='neg_mean_squared_error', error_score='raise')\n",
    "grid_search_lr.fit(X_train, Y_train)\n",
    "\n",
    "print('Best Hyperparameters for Linear Regression:', grid_search_lr.best_params_)\n",
    "print('Best Score (MSE):', -grid_search_lr.best_score_)\n",
    "\n",
    "# Use the best model from GridSearchCV\n",
    "best_lr_model = grid_search_lr.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for Random Forest: {'regressor__bootstrap': True, 'regressor__max_depth': None, 'regressor__min_samples_leaf': 4, 'regressor__min_samples_split': 10, 'regressor__n_estimators': 100}\n",
      "Best Score (MSE): 1218106464789.3225\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters for Random Forest\n",
    "param_grid_rf = {\n",
    "    'regressor__n_estimators': [50, 100, 200],      # Number of trees\n",
    "    'regressor__max_depth': [None, 10, 20, 30],     # Maximum depth of each tree\n",
    "    'regressor__min_samples_split': [2, 5, 10],     # Minimum samples required to split a node\n",
    "    'regressor__min_samples_leaf': [1, 2, 4],       # Minimum samples required at a leaf node\n",
    "    'regressor__bootstrap': [True, False]           # Whether bootstrap samples are used\n",
    "}\n",
    "\n",
    "# GridSearchCV for Random Forest\n",
    "grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_rf.fit(X_train, Y_train)\n",
    "\n",
    "print('Best Hyperparameters for Random Forest:', grid_search_rf.best_params_)\n",
    "print('Best Score (MSE):', -grid_search_rf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Linear Regression model saved as best_linear_model.pkl\n",
      "Best Random Forest model saved as best_random_forest_model.pkl\n"
     ]
    }
   ],
   "source": [
    "## 7. Saving the Best Models\n",
    "\n",
    "# Saving the best Linear Regression model\n",
    "best_lr_model = lr if lr_r2 > rf_r2 else rf  # Choose the better model\n",
    "with open('best_linear_model.pkl', 'wb') as file:\n",
    "    pickle.dump(lr, file)\n",
    "print('Best Linear Regression model saved as best_linear_model.pkl')\n",
    "\n",
    "# Saving the best Random Forest model\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "with open('best_random_forest_model.pkl', 'wb') as file:\n",
    "    pickle.dump(best_rf_model, file)\n",
    "print('Best Random Forest model saved as best_random_forest_model.pkl')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded Model: best_linear_model.pkl\n",
      "RMSE: 1345743.53, MAE: 960709.25, R²: 0.64\n",
      "\n",
      "\n",
      "Loaded Model: best_random_forest_model.pkl\n",
      "RMSE: 1425033.27, MAE: 1007792.96, R²: 0.60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 8. Loading and Testing Saved Models\n",
    "def load_and_test_model(filename, X_test, Y_test):\n",
    "    with open(filename, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    predictions = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(Y_test, predictions))\n",
    "    mae = mean_absolute_error(Y_test, predictions)\n",
    "    r2 = r2_score(Y_test, predictions)\n",
    "    print(f'\\nLoaded Model: {filename}')\n",
    "    print(f'RMSE: {rmse:.2f}, MAE: {mae:.2f}, R²: {r2:.2f}\\n')\n",
    "\n",
    "# Test the saved models\n",
    "load_and_test_model('best_linear_model.pkl', X_test, Y_test)\n",
    "load_and_test_model('best_random_forest_model.pkl', X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
